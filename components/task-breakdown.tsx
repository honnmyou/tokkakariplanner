"use client"

import type React from "react"

import { useState, useRef, useEffect, useCallback } from "react"
import { Button } from "@/components/ui/button"
import { Textarea } from "@/components/ui/textarea"
import { Card, CardContent } from "@/components/ui/card"
import { Mic, MicOff, AlertCircle, Loader2 } from "lucide-react"
import { Alert, AlertDescription } from "@/components/ui/alert"
import type { Task } from "@/types/task"
import { TaskBreakdownResults } from "./task-breakdown-results"
import { StatusBar } from "@/components/status-bar"
import { breakdownTaskWithAI } from "@/lib/task-breakdown-ai"

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  start(): void
  stop(): void
  abort(): void
  onresult: (event: SpeechRecognitionEvent) => void
  onerror: (event: SpeechRecognitionErrorEvent) => void
  onstart: () => void
  onend: () => void
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList
  resultIndex: number
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string
  message: string
}

interface SpeechRecognitionResultList {
  length: number
  item(index: number): SpeechRecognitionResult
  [index: number]: SpeechRecognitionResult
  [index: number]: SpeechRecognitionResult
}

interface SpeechRecognitionResult {
  length: number
  item(index: number): SpeechRecognitionAlternative
  [index: number]: SpeechRecognitionAlternative
  [index: number]: SpeechRecognitionAlternative
  isFinal: boolean
}

interface SpeechRecognitionAlternative {
  transcript: string
  confidence: number
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition
    webkitSpeechRecognition: new () => SpeechRecognition
  }
}

interface TaskBreakdownProps {
  task: Task
  onBack: () => void
  onTasksGenerated: (tasks: string[], isBreakdown?: boolean) => void
  onBackToHome?: () => void
  onTaskCompleted?: (taskId: string) => void
  tutorialStep?: string | null
  onTutorialStepComplete?: (step: string) => void
}

export function TaskBreakdown({
  task,
  onBack,
  onTasksGenerated,
  onBackToHome,
  onTaskCompleted,
  tutorialStep,
  onTutorialStepComplete,
}: TaskBreakdownProps) {
  const [text, setText] = useState("")
  const [interimText, setInterimText] = useState("")
  const [isRecording, setIsRecording] = useState(false)
  const [isSupported, setIsSupported] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [removeFillers, setRemoveFillers] = useState(true)
  const [generatedTasks, setGeneratedTasks] = useState<string[]>([])
  const [isProcessing, setIsProcessing] = useState(false)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const isRecordingRef = useRef(false)
  const lastClickTime = useRef(0)
  const textareaRef = useRef<HTMLTextAreaElement>(null)
  const [showResults, setShowResults] = useState(false)
  const [isManuallyEditing, setIsManuallyEditing] = useState(false)
  const lastCursorPosition = useRef(0)
  const [isInitializing, setIsInitializing] = useState(false)

  // LocalStorage key for saving text
  const storageKey = `task-breakdown-text-${task.id}`

  // Tutorial: voice-input-demoã‚¹ãƒ†ãƒƒãƒ—ã§è‡ªå‹•çš„ã«ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›
  useEffect(() => {
    if (tutorialStep === "voice-input-demo" && !text.trim()) {
      // 1ç§’å¾Œã«ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•å…¥åŠ›
      setTimeout(() => {
        const sampleText =
          "ãƒ—ãƒ¬ã‚¼ãƒ³è³‡æ–™ã‚’ä½œæˆã—ãŸã„ã§ã™ã€‚å†…å®¹ã¯æ–°å•†å“ã®ç´¹ä»‹ã§ã€10åˆ†ç¨‹åº¦ã®ç™ºè¡¨ã‚’äºˆå®šã—ã¦ã„ã¾ã™ã€‚ã‚¹ãƒ©ã‚¤ãƒ‰ã¯10æšç¨‹åº¦ã§ã€ã‚°ãƒ©ãƒ•ã‚„ç”»åƒã‚‚å«ã‚ãŸã„ã¨æ€ã„ã¾ã™ã€‚æ¥é€±ã®é‡‘æ›œæ—¥ã¾ã§ã«å®Œæˆã•ã›ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        setText(sampleText)

        // è‡ªå‹•é€²è¡Œã‚’å‰Šé™¤ - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¾ã§å¾…ã¤
        // setTimeout(() => {
        //   if (onTutorialStepComplete) {
        //     onTutorialStepComplete("voice-input-demo")
        //   }
        // }, 2000)
      }, 1000)
    }
  }, [tutorialStep, onTutorialStepComplete, text])

  // Tutorial: breakdown submission monitoring
  useEffect(() => {
    if (tutorialStep === "breakdown-submit" && showResults) {
      setTimeout(() => {
        if (onTutorialStepComplete) {
          onTutorialStepComplete("breakdown-submit")
        }
      }, 1000)
    }
  }, [showResults, tutorialStep, onTutorialStepComplete])

  // Load saved text from localStorage on mount
  useEffect(() => {
    try {
      const savedText = localStorage.getItem(storageKey)
      if (savedText && !tutorialStep) {
        setText(savedText)
        console.log("Loaded saved text from localStorage:", savedText.length, "characters")
      }
    } catch (error) {
      console.error("Failed to load saved text:", error)
    }
  }, [storageKey, tutorialStep])

  // Save text to localStorage whenever it changes
  useEffect(() => {
    if (text.trim() && !tutorialStep) {
      try {
        localStorage.setItem(storageKey, text)
        console.log("Saved text to localStorage:", text.length, "characters")
      } catch (error) {
        console.error("Failed to save text:", error)
      }
    }
  }, [text, storageKey, tutorialStep])

  // ãƒ•ã‚£ãƒ©ãƒ¼é™¤å»é–¢æ•°
  const removeFillerWords = useCallback(
    (text: string): string => {
      if (!removeFillers) return text

      // åŸºæœ¬çš„ãªãƒ•ã‚£ãƒ©ãƒ¼ã®ã¿ã«é™å®š
      const fillerPatterns = [
        /\bãˆãƒ¼\b/g,
        /\bã‚ã®ãƒ¼\b/g,
        /\bãˆã£ã¨\b/g,
        /\bã†ãƒ¼ã‚“\b/g,
        /\bã¾ã‚\b/g,
        /\bãã®ãƒ¼\b/g,
        /\bãªã‚“ã‹\b/g,
        /\bã£ã¦ã„ã†ã‹\b/g,
        /\bã»ã‚‰\b/g,
      ]

      let cleanedText = text
      fillerPatterns.forEach((pattern) => {
        cleanedText = cleanedText.replace(pattern, "")
      })

      // è¤‡æ•°ã®ç©ºç™½ã‚’å˜ä¸€ã®ç©ºç™½ã«å¤‰æ›
      cleanedText = cleanedText.replace(/\s+/g, " ").trim()
      return cleanedText
    },
    [removeFillers],
  )

  const insertTextAtCursor = useCallback(
    (newText: string, isInterim = false) => {
      const textarea = textareaRef.current
      if (!textarea) {
        if (isInterim) {
          setInterimText(newText)
        } else {
          setText((prev) => prev + newText + " ")
          setInterimText("")
        }
        return
      }

      const start = lastCursorPosition.current
      const currentText = text

      if (isInterim) {
        // é€”ä¸­çµæœã®å ´åˆã¯ã€interimTextã¨ã—ã¦ä¿å­˜
        setInterimText(newText)
      } else {
        // ç¢ºçµæœã®å ´åˆã¯ã€å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
        const beforeCursor = currentText.substring(0, start)
        const afterCursor = currentText.substring(start)
        const updatedText = beforeCursor + newText + " " + afterCursor

        setText(updatedText)
        setInterimText("")

        // ã‚«ãƒ¼ã‚½ãƒ«ä½ç½®ã‚’æ›´æ–°
        setTimeout(() => {
          const newCursorPosition = start + newText.length + 1
          lastCursorPosition.current = newCursorPosition
          textarea.setSelectionRange(newCursorPosition, newCursorPosition)
          textarea.focus()
        }, 0)
      }
    },
    [text],
  )

  // éŸ³å£°èªè­˜ã®å®Œå…¨ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  const cleanupRecognition = useCallback(() => {
    console.log("Cleaning up speech recognition...")
    if (recognitionRef.current) {
      try {
        recognitionRef.current.abort()
      } catch (e) {
        console.log("Error during cleanup:", e)
      }
      recognitionRef.current = null
    }
    setIsRecording(false)
    isRecordingRef.current = false
    setInterimText("")
    setIsInitializing(false)
  }, [])

  // éŸ³å£°èªè­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã™ã‚‹é–¢æ•°
  const createSpeechRecognition = useCallback(() => {
    console.log("Creating new speech recognition instance...")

    if (typeof window === "undefined") {
      console.log("Window is undefined")
      return null
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    if (!SpeechRecognition) {
      console.log("SpeechRecognition not available")
      return null
    }

    const recognition = new SpeechRecognition()

    // éŸ³å£°èªè­˜ã®è¨­å®šã‚’èª¿æ•´ã—ã¦æ–‡ãŒåˆ‡ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = "ja-JP"

    // è¿½åŠ è¨­å®šã§éŸ³å£°èªè­˜ã®ç¶™ç¶šæ€§ã‚’å‘ä¸Š
    if ("maxAlternatives" in recognition) {
      ;(recognition as any).maxAlternatives = 1
    }

    console.log("Speech recognition configured:", {
      continuous: recognition.continuous,
      interimResults: recognition.interimResults,
      lang: recognition.lang,
    })

    recognition.onstart = () => {
      console.log("ğŸ¤ Speech recognition STARTED")
      setIsRecording(true)
      isRecordingRef.current = true
      setError(null)
      setIsManuallyEditing(false)
      setIsInitializing(false)

      // Tutorial: éŸ³å£°å…¥åŠ›é–‹å§‹æ™‚ã«breakdown-screenã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Œäº†
      if (tutorialStep === "breakdown-screen" && onTutorialStepComplete) {
        onTutorialStepComplete("breakdown-screen")
      }
    }

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      console.log("ğŸ”Š Speech recognition result received, results count:", event.results.length)
      let finalTranscript = ""
      let interimTranscript = ""

      // å…¨ã¦ã®çµæœã‚’å‡¦ç†ï¼ˆresultIndexã‹ã‚‰ã§ã¯ãªã0ã‹ã‚‰ï¼‰
      for (let i = 0; i < event.results.length; i++) {
        const result = event.results[i]
        const transcript = result[0].transcript

        console.log(`ğŸ“ Result ${i}: isFinal=${result.isFinal}, transcript="${transcript}"`)

        if (result.isFinal) {
          finalTranscript += transcript
        } else {
          interimTranscript += transcript
        }
      }

      if (!isManuallyEditing) {
        if (interimTranscript.trim()) {
          const cleanedInterim = removeFillerWords(interimTranscript)
          console.log("âœï¸ Inserting interim text:", cleanedInterim)
          insertTextAtCursor(cleanedInterim, true)
        }

        if (finalTranscript.trim()) {
          const cleanedFinal = removeFillerWords(finalTranscript)
          if (cleanedFinal.trim()) {
            console.log("âœ… Inserting final text:", cleanedFinal)
            insertTextAtCursor(cleanedFinal, false)
          }
        }
      }
    }

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.log("âŒ Speech recognition error:", event.error, event.message)

      setIsRecording(false)
      isRecordingRef.current = false
      setInterimText("")
      setIsInitializing(false)

      switch (event.error) {
        case "not-allowed":
          setError("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
          break
        case "no-speech":
          console.log("No speech detected - this is normal, will restart automatically")
          // no-speechã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è‡ªå‹•çš„ã«å†é–‹ã‚’è©¦ã¿ã‚‹
          setTimeout(() => {
            if (!isRecordingRef.current && recognitionRef.current) {
              try {
                console.log("ğŸ”„ Auto-restarting speech recognition after no-speech...")
                recognitionRef.current.start()
              } catch (e) {
                console.log("Failed to auto-restart:", e)
              }
            }
          }, 1000)
          break
        case "audio-capture":
          setError("ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒã‚¤ã‚¯ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
          break
        case "network":
          setError("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
          break
        case "aborted":
          console.log("Speech recognition was aborted")
          break
        default:
          console.error("Unknown speech recognition error:", event.error)
          break
      }
    }

    recognition.onend = () => {
      console.log("ğŸ›‘ Speech recognition ENDED")
      setIsRecording(false)
      isRecordingRef.current = false
      setInterimText("")
      setIsInitializing(false)
      // ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚¯ãƒªã‚¢ï¼ˆå†åˆ©ç”¨ä¸å¯ã®ãŸã‚ï¼‰
      recognitionRef.current = null
    }

    return recognition
  }, [removeFillerWords, insertTextAtCursor, isManuallyEditing, tutorialStep, onTutorialStepComplete])

  // åˆæœŸåŒ–
  useEffect(() => {
    if (typeof window === "undefined") return

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    setIsSupported(!!SpeechRecognition)
    console.log("Speech recognition supported:", !!SpeechRecognition)

    // Cleanup on unmount
    return () => {
      cleanupRecognition()
    }
  }, [cleanupRecognition])

  // startRecordingé–¢æ•°ã‚’æ”¹å–„
  const startRecording = useCallback(async () => {
    console.log("ğŸš€ Starting recording process...")

    if (isRecordingRef.current || isInitializing) {
      console.log("Already recording or initializing, skipping...")
      return
    }

    // Prevent rapid clicking
    const now = Date.now()
    if (now - lastClickTime.current < 1000) {
      console.log("Preventing rapid clicking")
      return
    }
    lastClickTime.current = now

    setIsInitializing(true)
    setError(null)

    try {
      console.log("ğŸ¤ Requesting microphone permission...")
      // ãƒã‚¤ã‚¯ã®æ¨©é™ã‚’æ¯å›ç¢ºèª
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      console.log("âœ… Microphone permission granted")

      // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å³åº§ã«åœæ­¢ï¼ˆæ¨©é™ç¢ºèªã®ãŸã‚ã ã‘ã«ä½¿ç”¨ï¼‰
      stream.getTracks().forEach((track) => track.stop())

      // æ—¢å­˜ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å®Œå…¨ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      cleanupRecognition()

      // å°‘ã—å¾…ã£ã¦ã‹ã‚‰æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
      await new Promise((resolve) => setTimeout(resolve, 100))

      console.log("ğŸ”§ Creating new recognition instance...")
      const recognition = createSpeechRecognition()
      if (!recognition) {
        throw new Error("Speech recognition not supported")
      }

      recognitionRef.current = recognition

      // ã‚«ãƒ¼ã‚½ãƒ«ä½ç½®ã‚’è¨˜éŒ²
      if (textareaRef.current) {
        lastCursorPosition.current = textareaRef.current.selectionStart
        console.log("ğŸ“ Cursor position recorded:", lastCursorPosition.current)
      }

      // éŸ³å£°èªè­˜ã‚’é–‹å§‹
      console.log("â–¶ï¸ Starting speech recognition...")
      recognition.start()
    } catch (err) {
      console.error("âŒ Failed to start recording:", err)
      setIsInitializing(false)

      if (err instanceof Error) {
        if (err.name === "NotAllowedError") {
          setError("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        } else if (err.name === "NotFoundError") {
          setError("ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒã‚¤ã‚¯ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        } else {
          setError("éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        }
      } else {
        setError("éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
      }
    }
  }, [createSpeechRecognition, cleanupRecognition, isInitializing])

  // stopRecordingé–¢æ•°ã‚’æ”¹å–„
  const stopRecording = useCallback(() => {
    console.log("â¹ï¸ Stopping recording...")

    if (!recognitionRef.current || !isRecordingRef.current) {
      console.log("Cannot stop recording: no recognition instance or not recording")
      return
    }

    try {
      console.log("ğŸ›‘ Calling recognition.stop()...")
      recognitionRef.current.stop()
    } catch (err) {
      console.error("âŒ Failed to stop recording:", err)
      // å¼·åˆ¶çš„ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      cleanupRecognition()
    }
  }, [cleanupRecognition])

  const toggleRecording = useCallback(() => {
    console.log("ğŸ”„ Toggle recording, current state:", {
      isRecording: isRecordingRef.current,
      isInitializing: isInitializing,
    })

    if (isRecordingRef.current) {
      stopRecording()
    } else {
      startRecording()
    }
  }, [startRecording, stopRecording, isInitializing])

  // ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ä¸­ã®åˆ¶å¾¡ã‚’è¿½åŠ 
  const isTutorialBreakdownEnabled = (actionType: string): boolean => {
    if (!tutorialStep) return true

    switch (tutorialStep) {
      case "breakdown-screen":
      case "voice-input":
      case "voice-input-demo":
        return actionType === "voice-input" || actionType === "text-input"
      case "breakdown-submit":
        return actionType === "breakdown-submit" && text.trim().length > 0
      default:
        return false
    }
  }

  const handleBreakdown = async () => {
    if (!text.trim()) return

    // Stop recording before processing
    if (isRecordingRef.current) {
      stopRecording()
    }

    setIsProcessing(true)
    setError(null)

    try {
      // å®Ÿéš›ã®AI APIã‚’å‘¼ã³å‡ºã—
      const result = await breakdownTaskWithAI(task.title, text.trim())

      if (result.success && result.tasks.length > 0) {
        setGeneratedTasks(result.tasks)
        setShowResults(true)
      } else {
        setError(result.error || "ã‚¿ã‚¹ã‚¯ã®åˆ†è§£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
      }
    } catch (error) {
      console.error("Task breakdown error:", error)
      setError("ã‚¿ã‚¹ã‚¯ã®åˆ†è§£ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    } finally {
      setIsProcessing(false)
    }
  }

  const clearError = () => {
    setError(null)
  }

  const handleBackFromResults = () => {
    setShowResults(false)
  }

  const handleStartFromResults = () => {
    onBack()
  }

  const handleTextChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    const newValue = e.target.value
    setText(newValue)
    setInterimText("") // æ‰‹å‹•ç·¨é›†æ™‚ã¯é€”ä¸­çµæœã‚’ã‚¯ãƒªã‚¢
    setIsManuallyEditing(true)

    // ã‚«ãƒ¼ã‚½ãƒ«ä½ç½®ã‚’æ›´æ–°
    setTimeout(() => {
      if (textareaRef.current) {
        lastCursorPosition.current = textareaRef.current.selectionStart
      }
    }, 0)
  }

  const handleTextFocus = () => {
    setIsManuallyEditing(true)
    // ã‚«ãƒ¼ã‚½ãƒ«ä½ç½®ã‚’è¨˜éŒ²
    if (textareaRef.current) {
      lastCursorPosition.current = textareaRef.current.selectionStart
    }
  }

  const handleTextBlur = () => {
    // ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ãŒå¤–ã‚ŒãŸå¾Œã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰æ‰‹å‹•ç·¨é›†ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
    setTimeout(() => {
      setIsManuallyEditing(false)
    }, 500)
  }

  const handleClearText = () => {
    setText("")
    setInterimText("")
    // LocalStorageã‹ã‚‰ã‚‚å‰Šé™¤
    try {
      localStorage.removeItem(storageKey)
      console.log("Cleared text from localStorage")
    } catch (error) {
      console.error("Failed to clear text from localStorage:", error)
    }
    // éŸ³å£°èªè­˜ã‚‚åœæ­¢
    if (isRecordingRef.current) {
      stopRecording()
    }
  }

  if (showResults) {
    return (
      <TaskBreakdownResults
        task={task}
        generatedTasks={generatedTasks}
        onBack={handleBackFromResults}
        onStart={handleStartFromResults}
        onTasksGenerated={onTasksGenerated}
        onBackToHome={onBackToHome}
        onTaskCompleted={onTaskCompleted}
        tutorialStep={tutorialStep}
        onTutorialStepComplete={onTutorialStepComplete}
      />
    )
  }

  // è¡¨ç¤ºç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆ + é€”ä¸­çµæœï¼‰
  const displayText = text + interimText

  return (
    <div className="breakdown-container min-h-screen bg-gray-50 flex flex-col">
      {/* Status Bar */}
      <StatusBar />

      {/* Header */}
      <div className="bg-teal-600 px-4 py-3 flex items-center justify-between flex-shrink-0">
        <Button variant="ghost" size="icon" onClick={onBack} className="text-white hover:bg-teal-700">
          <img src="/images/back-arrow.png" alt="æˆ»ã‚‹" className="w-6 h-6 filter brightness-0 invert" />
        </Button>
        <Button
          variant="outline"
          className={`breakdown-submit text-teal-600 border-white bg-white hover:bg-gray-100 disabled:opacity-50 ${
            tutorialStep && !isTutorialBreakdownEnabled("breakdown-submit") ? "cursor-not-allowed" : ""
          }`}
          onClick={handleBreakdown}
          disabled={
            !text.trim() ||
            isProcessing ||
            (tutorialStep === "breakdown-submit" && !isTutorialBreakdownEnabled("breakdown-submit"))
          }
        >
          {isProcessing ? (
            <>
              <Loader2 className="w-4 h-4 mr-2 animate-spin" />
              åˆ†è§£ä¸­...
            </>
          ) : (
            "åˆ†è§£"
          )}
        </Button>
      </div>

      {/* Content - ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ */}
      <div className="flex-1 min-h-0 overflow-y-auto">
        <div className="p-3 pb-40">
          {" "}
          {/* éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ã®ãŸã‚ã®ååˆ†ãªä¸‹éƒ¨ä½™ç™½ */}
          <h1 className="text-lg font-bold mb-3 text-slate-800">{task.title}</h1>
          {/* Error Alert */}
          {error && (
            <Alert variant="destructive" className="mb-3">
              <AlertCircle className="h-4 w-4" />
              <AlertDescription className="flex justify-between items-center">
                <span className="text-sm">{error}</span>
                <Button variant="ghost" size="sm" onClick={clearError}>
                  Ã—
                </Button>
              </AlertDescription>
            </Alert>
          )}
          {/* Instructions */}
          <Card className="mb-3">
            <CardContent className="p-3">
              <p className="text-sm text-gray-700 mb-2">
                ã“ã®ã‚¿ã‚¹ã‚¯ã§ã€Œã‚ãªãŸãŒã‚„ã‚‹ã“ã¨ã€ã¨ã€Œç›®æŒ‡ã™ã‚´ãƒ¼ãƒ«ã€ã‚’æ•™ãˆã¦ãã ã•ã„
              </p>
              <div className="bg-gray-100 p-2 rounded text-xs text-gray-600">
                ğŸ’¬ ã‚´ãƒ¼ãƒ«ãŒå…·ä½“çš„ãªã»ã©ã€ã‚¿ã‚¹ã‚¯ã‚‚ç´°ã‹ãåˆ†ã‘ã‚„ã™ããªã‚Šã¾ã™ï¼
                <br />ğŸ¤ éŸ³å£°å…¥åŠ›ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã©ã¡ã‚‰ã§ã‚‚OKã§ã™
              </div>
            </CardContent>
          </Card>
          {/* Processing Status */}
          {isProcessing && (
            <Card className="mb-3">
              <CardContent className="p-3">
                <div className="flex items-center gap-3">
                  <Loader2 className="w-5 h-5 animate-spin text-teal-600" />
                  <div>
                    <p className="text-sm font-medium text-gray-800">AIãŒã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ä¸­...</p>
                    <p className="text-xs text-gray-600">åˆ†ã‹ã‚Šã‚„ã™ã„ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†ã‘ã¦ã„ã¾ã™</p>
                  </div>
                </div>
              </CardContent>
            </Card>
          )}
          {/* Input Area */}
          <Card className="mb-3">
            <CardContent className="p-3">
              <div className="flex items-center justify-between mb-2">
                <div className="flex items-center space-x-3">
                  <label htmlFor="filler-toggle" className="text-xs font-medium text-gray-700">
                    ãƒ•ã‚£ãƒ©ãƒ¼é™¤å»
                  </label>
                  <button
                    id="filler-toggle"
                    type="button"
                    className={`relative inline-flex h-5 w-9 items-center rounded-full transition-colors ${
                      removeFillers ? "bg-teal-600" : "bg-gray-200"
                    }`}
                    onClick={() => setRemoveFillers(!removeFillers)}
                  >
                    <span
                      className={`inline-block h-3 w-3 transform rounded-full bg-white transition-transform ${
                        removeFillers ? "translate-x-5" : "translate-x-1"
                      }`}
                    />
                  </button>
                </div>

                <div className="flex items-center space-x-2">
                  <Button
                    variant="outline"
                    size="sm"
                    onClick={handleClearText}
                    disabled={!text.trim() && !interimText.trim()}
                    className="text-xs h-7 bg-transparent"
                  >
                    ã‚¯ãƒªã‚¢
                  </Button>
                  <span className="text-xs text-gray-500">{displayText.length}æ–‡å­—</span>
                </div>
              </div>

              <div className="relative">
                <Textarea
                  ref={textareaRef}
                  value={displayText}
                  onChange={handleTextChange}
                  onFocus={handleTextFocus}
                  onBlur={handleTextBlur}
                  placeholder="ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã‹ã€ä¸‹ã®ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã§éŸ³å£°å…¥åŠ›ã—ã¦ãã ã•ã„..."
                  className={`tutorial-text-input min-h-[200px] resize-none text-sm ${
                    tutorialStep && !isTutorialBreakdownEnabled("text-input") ? "opacity-50 cursor-not-allowed" : ""
                  }`}
                  disabled={tutorialStep && !isTutorialBreakdownEnabled("text-input")}
                />
                {interimText && (
                  <div className="absolute bottom-2 right-2 bg-blue-100 text-blue-700 px-2 py-1 rounded text-xs">
                    èªè­˜ä¸­...
                  </div>
                )}
              </div>

              {removeFillers && (
                <div className="bg-blue-50 p-2 rounded text-xs text-blue-700 mt-2">
                  ğŸ’¡ ãƒ•ã‚£ãƒ©ãƒ¼é™¤å»ãŒæœ‰åŠ¹ã§ã™ã€‚ã€Œãˆãƒ¼ã€ã€Œã‚ãƒ¼ã€ã€Œã†ãƒ¼ã‚“ã€ãªã©ã®ä¸è¦ãªè¨€è‘‰ã¯è‡ªå‹•çš„ã«é™¤å»ã•ã‚Œã¾ã™ã€‚
                </div>
              )}

              {text && !tutorialStep && (
                <div className="bg-green-50 p-2 rounded text-xs text-green-700 mt-2">
                  ğŸ’¾ å…¥åŠ›å†…å®¹ã¯è‡ªå‹•çš„ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™
                </div>
              )}

              {!isSupported && (
                <Alert className="mt-2">
                  <AlertCircle className="h-4 w-4" />
                  <AlertDescription className="text-xs">
                    ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚Chromeã€Safariã€Edgeã‚’ãŠè©¦ã—ãã ã•ã„ã€‚
                    <br />
                    ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¯å¼•ãç¶šãã”åˆ©ç”¨ã„ãŸã ã‘ã¾ã™ã€‚
                  </AlertDescription>
                </Alert>
              )}
            </CardContent>
          </Card>
        </div>
      </div>

      {/* Voice Input Button - å›ºå®šä½ç½® */}
      <div className="fixed bottom-6 left-1/2 transform -translate-x-1/2 z-10">
        <Button
          size="lg"
          className={`voice-input-button w-14 h-14 rounded-full transition-all duration-200 ${
            isRecording
              ? "bg-red-500 hover:bg-red-600 animate-pulse shadow-lg"
              : isInitializing
                ? "bg-yellow-500 hover:bg-yellow-600 shadow-lg"
                : isSupported
                  ? "bg-teal-600 hover:bg-teal-700 shadow-md"
                  : "bg-gray-400 cursor-not-allowed shadow-md"
          } ${tutorialStep && !isTutorialBreakdownEnabled("voice-input") ? "opacity-50 cursor-not-allowed" : ""}`}
          onClick={toggleRecording}
          disabled={!isSupported || isProcessing || (tutorialStep && !isTutorialBreakdownEnabled("voice-input"))}
        >
          {isInitializing ? (
            <Loader2 className="h-7 w-7 text-white animate-spin" />
          ) : isRecording ? (
            <MicOff className="h-7 w-7 text-white" />
          ) : (
            <Mic className="text-white w-[55px] h-[55px]" />
          )}
        </Button>
      </div>

      {/* Recording Status */}
      {isRecording && (
        <div className="fixed bottom-24 left-1/2 transform -translate-x-1/2 z-10">
          <div className="bg-red-500 text-white px-3 py-1 rounded-full text-xs animate-pulse">
            ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜ä¸­
          </div>
        </div>
      )}

      {/* Initializing Status */}
      {isInitializing && !isRecording && (
        <div className="fixed bottom-24 left-1/2 transform -translate-x-1/2 z-10">
          <div className="bg-yellow-500 text-white px-3 py-1 rounded-full text-xs">ğŸ”„ éŸ³å£°èªè­˜ã‚’æº–å‚™ä¸­...</div>
        </div>
      )}
    </div>
  )
}
